{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c398f10c",
   "metadata": {},
   "source": [
    "### Teoretiska fr√•gor\n",
    "1. Kalle delar upp sin data i ‚ÄùTr√§ning‚Äù, ‚ÄùValidering‚Äù och ‚ÄùTest‚Äù, vad anv√§nds respektive del f√∂r?<br> \n",
    "\n",
    "<b>Tr√§ning</b> (cirka 70%) anv√§nds f√∂r att tr√§na modellen p√• den aktuella datan, f√∂r att p√• s√• vis kunna predicta framtida datapunkter. <br>\n",
    "<b>Validering</b> (cirka 15%) anv√§nds f√∂r att testa modellens presterande under tr√§ningen, innan en g√•r vidare till n√§sta steg med ny data. Genom valideringsdatan kan man justera hyperparametrar och overfitting, och p√• s√• vis se till att modellen inte bara l√§r sig tr√§ningsdatan utan √§ven tar h√∂jd f√∂r ok√§nd data.<br> <b>Test</b> (cirka 15%) anv√§nds f√∂r att just testa modellens prestande p√• ny ok√§nd data, efter att tr√§ningen √§r klar.<br> \n",
    "\n",
    "2. Julia delar upp sin data i tr√§ning och test. P√• tr√§ningsdatan s√• tr√§nar hon tre modeller; ‚ÄùLinj√§r Regression‚Äù, ‚ÄùLasso regression‚Äù och en ‚ÄùRandom Forest modell‚Äù. Hur skall hon v√§lja vilken av de tre modellerna hon skall forts√§tta anv√§nda n√§r hon inte skapat ett explicit ‚Äùvalideringsdataset‚Äù?<br>\n",
    "\n",
    "Genom att anv√§nda Cross Validation. K-Fold Cross Validation med hj√§lp av sklearn.model_selection och cross_val_score ger en bild av vilken modell som ger l√§gst MSE, Mean Squared Error. Om tv√• modeller har v√§ldigt lika eller samma MSE s√• v√§ljer Julia den enklare eller snabbare av de tv√•. Vid √∂veranpassning anv√§nder hon den modell som √§r mest generell, s√•som Lasso som √§r regulariserad. Julia g√∂r klokt i att komma ih√•g att anv√§nda minustecken resultatet p√• neg_mean_squared_error f√∂r att f√• r√§tt resultat.<br>\n",
    "\n",
    "3. Vad √§r ‚Äùregressionsproblem? Kan du ge n√•gra exempel p√• modeller som anv√§nds och potentiella till√§mpningsomr√•den?<br>\n",
    "\n",
    "Regressionsproblem betyder att f√∂ruts√§ga ett kontinuerligt v√§rde s√•som f√∂rs√§ljningsint√§kter, bostadspriser och temperaturdiagnoser, baserat p√• datan som modellen tr√§nas p√•. Vanliga exempel p√• modeller √§r:<br>\n",
    "<b>Linear Regression</b> anv√§nds f√∂r att som namnet antyder modellera linj√§ra samband.<br>\n",
    "<b>Lasso Regression</b> anv√§nds p√• samma s√§tt som ovan men med regularisering, det vill s√§ga att den f√∂rs√∂ker g√∂ra modellen enklare genom att straffa alltf√∂r store koefficienter och s√§tta ner dom √§nda till 0. Det √§r detta som f√∂rhindrar √∂veranpassning, Overfitting.<br>\n",
    "<b>Random Forest Regression</b> tr√§nar slumpm√§ssigt valda delar av datan p√• m√•nga s.k. beslutstr√§d, d√§r varje tr√§d g√∂r sin egen f√∂ruts√§gelse. Till sist tas medelv√§rdet av alla tr√§dens f√∂ruts√§gelser - denna metod g√∂r sig extra bra n√§r man hanterar komplexa och stora datam√§ngder.<br>\n",
    "\n",
    "4. Hur kan du tolka RMSE och vad anv√§nds det till?<br>\n",
    "\n",
    "RMSE (Root Mean Squared Error) anv√§nds f√∂r att ber√§kna hur stor regressionsmodellens avvikelse √§r fr√•n de verkliga v√§rdena. Ju l√§gre RMSE, desto b√§ttre kan modellen f√∂rutse framtida data. Eftersom RMSE m√§ter genomsnittligt fel men ocks√• kvadrerar det s√• syns stora fel tydligare.<br>\n",
    "\n",
    "5. Vad √§r ‚Äùklassificieringsproblem? Kan du ge n√•gra exempel p√• modeller som anv√§nds och potentiella till√§mpningsomr√•den? Vad √§r en ‚ÄùConfusion Matrix‚Äù?<br>\n",
    "\n",
    "Klassificeringsproblem inneb√§r att f√∂rutsp√• indelning i diskreta kategorier, till exempel bin√§ra (sjuk/frisk) och multiklass (katt/r√•tta/kamel). Modeller som anv√§nds √§r till exempel:<br>\n",
    "Random Forest, Logistisk regression, Neurala n√§tverk (MLP, CNN).<br>\n",
    "Confusion Matrix √§r en tabell med fyra celler: TP (True Positives), FP (False Positives), TN (True Negatives) och FN (False Negatives). Denna visar hur m√•nga f√∂ruts√§gelser som √§r korrekta respektive felaktiga.\n",
    "\n",
    "6. Vad √§r K-means modellen f√∂r n√•got? Ge ett exempel p√• vad det kan till√§mpas p√•.<br>\n",
    "\n",
    "K-means √§r en s√• kallad klustringsalgoritm d√§r datapunkter delas upp i K olika kluster baserat p√• dess avst√•nd. P√• s√• vis kan en tydligare bild uppst√• kring till exempel gruppindelning av sjukdomar i medicinsk data, dokumentklassificering likt skr√§ppostfilter, och kundsegmentering.<br>\n",
    "\n",
    "7. F√∂rklara (g√§rna med ett exempel): Ordinal encoding, one-hot encoding, dummy variable encoding. Se mappen ‚Äùl8‚Äù p√• GitHub om du beh√∂ver repetition.<br>\n",
    "\n",
    "<b>Ordinal Encoding</b> anv√§nds d√§r kategorierna har en inb√∂rdes ordning. Varje kategori ers√§tts med ett nummer.<br> <i>Exempel:</i> \"L√•g\" = 0, \"Medel\" = 1, \"H√∂g\" = 2.<br>\n",
    "<b>One-hot Encoding</b> passar d√§r varje kategori f√•r en egen kolumn med 1 eller 0 f√∂r aktiv eller inaktiv.<br> <i>Exempel:</i> \"L√•g\" = [1, 0, 0], \"Medel\" = [0, 1, 0], \"H√∂g\" = [0, 0, 1].<br>\n",
    "<b>Dummy Variable Encoding</b> √§r liknande One-hot encoding men tar h√∂jd f√∂r vissa analyser d√§r multikollinearitet kan skapa problem. H√§r tas en kategori bort och blir s√• kallad referenskategori. Om \"L√•g\" √§r referenskategori √§r \"Medel\" = 1, \"H√∂g\" = 0, om b√•da √§r 0: referenskategorin \"L√•g\".<br>\n",
    "\n",
    "8. G√∂ran p√•st√•r att datan antingen √§r ‚Äùordinal‚Äù eller ‚Äùnominal‚Äù. Julia s√§ger att detta m√•ste tolkas. Hon ger ett exempel med att f√§rger s√•som {r√∂d, gr√∂n, bl√•} generellt sett inte har n√•gon inb√∂rdes ordning (nominal) men om du har en r√∂d skjorta s√• √§r du vackrast p√• festen (ordinal) ‚Äì vem har r√§tt?<br>\n",
    "\n",
    "<b>Nominal data</b> best√•r inte av n√•gon inb√∂rdes ordning, till exempel har f√§rgerna r√∂d, bl√• och gr√∂n ingen rangordning rent objektivt. F√§rgerna kan dock tillskrivas en subjektiv rankning och blir d√• Ordinal.<br>\n",
    "<b>Ordinal data</b> √§r som ovan n√§mnt data som har en inb√∂rdes ranking, till exempel \"Fult\", \"Okej\", \"Vackrast\". Just att en r√∂d skjorta g√∂r en vackrast p√• festen √§r en subjektiv ranking, men likv√§l en ranking, d√§rav ordinal.\n",
    "\n",
    "9. Besvara f√∂ljande fr√•ga: Vad √§r Streamlit f√∂r n√•got och vad kan det anv√§ndas till?<br>\n",
    "\n",
    "<b>Streamlit</b> √§r ett Pythonbibliotek som snabbt kan skapa webbapplikationer f√∂r maskininl√§rning och visualisering av data. Det kan anv√§ndas p√• en uppsj√∂ av olika omr√•den, till exempel interaktiv maskininl√§rning, d√§r anv√§ndaren kan tr√§na, utv√§rdera och justera modeller i realtid. Genom anv√§ndning av Streamlit kan man skapa enkla och tydliga gr√§nssnitt till maskininl√§rningsmodeller eller andra Pythonbaserade applikationer, utan att f√∂r den delen kunna n√•got om frontendutveckling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a67f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0fc190a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation noggrannhet: [0.97128571 0.972      0.96978571 0.96642857 0.97278571]\n",
      "Medelv√§rde: 0.970457\n",
      "Standardavvikelse: 0.002244\n",
      "Slutlig KNN Noggrannhet (testset): 0.971286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1343\n",
      "           1       0.96      0.99      0.98      1600\n",
      "           2       0.97      0.97      0.97      1380\n",
      "           3       0.97      0.96      0.97      1433\n",
      "           4       0.97      0.96      0.97      1295\n",
      "           5       0.98      0.97      0.97      1273\n",
      "           6       0.98      0.99      0.99      1396\n",
      "           7       0.97      0.98      0.97      1503\n",
      "           8       0.99      0.94      0.96      1357\n",
      "           9       0.96      0.95      0.96      1420\n",
      "\n",
      "    accuracy                           0.97     14000\n",
      "   macro avg       0.97      0.97      0.97     14000\n",
      "weighted avg       0.97      0.97      0.97     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Ladda MNIST-datasetet\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)\n",
    "\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"].astype(np.uint8)\n",
    "\n",
    "# Normalisera data\n",
    "X = X / 255.0\n",
    "\n",
    "# üîπ Cross-validation innan train-test-split\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "cv_scores = cross_val_score(knn, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"Cross-validation noggrannhet: {cv_scores}\")\n",
    "print(f\"Medelv√§rde: {np.mean(cv_scores):.6f}\")\n",
    "print(f\"Standardavvikelse: {np.std(cv_scores):.6f}\")\n",
    "\n",
    "# üîπ Train-test-split f√∂r slutlig utv√§rdering\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "knn.fit(X_train, y_train)  # Tr√§na p√• hela tr√§ningsdatan\n",
    "\n",
    "# G√∂r prediktioner\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Utv√§rdera modellen\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Slutlig KNN Noggrannhet (testset): {accuracy:.6f}\")\n",
    "\n",
    "# Mer detaljerad utv√§rdering\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce04c64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation noggrannhet: [0.97057143 0.96842857 0.968      0.96685714 0.97385714]\n",
      "Medelv√§rde: 0.969543\n",
      "Standardavvikelse: 0.002470\n",
      "Slutlig Random Forest Noggrannhet (testset): 0.969429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1343\n",
      "           1       0.99      0.99      0.99      1600\n",
      "           2       0.95      0.97      0.96      1380\n",
      "           3       0.96      0.95      0.96      1433\n",
      "           4       0.97      0.97      0.97      1295\n",
      "           5       0.97      0.96      0.97      1273\n",
      "           6       0.98      0.98      0.98      1396\n",
      "           7       0.97      0.97      0.97      1503\n",
      "           8       0.96      0.96      0.96      1357\n",
      "           9       0.96      0.95      0.96      1420\n",
      "\n",
      "    accuracy                           0.97     14000\n",
      "   macro avg       0.97      0.97      0.97     14000\n",
      "weighted avg       0.97      0.97      0.97     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Ladda MNIST-datasetet\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)\n",
    "\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"].astype(np.uint8)\n",
    "\n",
    "# Normalisera data\n",
    "X = X / 255.0\n",
    "\n",
    "# üîπ Cross-validation innan train-test-split\n",
    "rf = RandomForestClassifier(n_estimators=400, random_state=42, n_jobs=-1)\n",
    "\n",
    "cv_scores = cross_val_score(rf, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"Cross-validation noggrannhet: {cv_scores}\")\n",
    "print(f\"Medelv√§rde: {np.mean(cv_scores):.6f}\")\n",
    "print(f\"Standardavvikelse: {np.std(cv_scores):.6f}\")\n",
    "\n",
    "# üîπ Train-test-split f√∂r slutlig utv√§rdering\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf.fit(X_train, y_train)  # Tr√§na p√• hela tr√§ningsdatan\n",
    "\n",
    "# G√∂r prediktioner\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Utv√§rdera modellen\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Slutlig Random Forest Noggrannhet (testset): {accuracy_rf:.6f}\")\n",
    "\n",
    "# Spara modellen\n",
    "joblib.dump(rf, 'random_forest_model.pkl')\n",
    "\n",
    "# Tr√§na p√• hela datasetet\n",
    "\n",
    "rf.fit(X, y)  # Tr√§na p√• hela datasetet inf√∂r produktionss√§ttning\n",
    "\n",
    "# Spara modellen\n",
    "joblib.dump(rf, 'random_forest_model_full_data.pkl')\n",
    "\n",
    "\n",
    "# Mer detaljerad utv√§rdering\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6cba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Extra Trees modell\n",
    "et = ExtraTreesClassifier(n_estimators=300, random_state=42)\n",
    "\n",
    "# Cross-validation\n",
    "cv_scores_et = cross_val_score(et, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "# Visa resultat\n",
    "print(f\"Cross-validation noggrannhet: {cv_scores_et}\")\n",
    "print(f\"Medelv√§rde: {cv_scores_et.mean():.6f}\")\n",
    "print(f\"Standardavvikelse: {cv_scores_et.std():.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
